from langchain.chat_models import init_chat_model
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime
import json
import const
# agent è¦ä½¿ç”¨ä½tempå—
model = init_chat_model(
    model="deepseek-chat",
    temperature=0.0,
    model_provider='openai',
    base_url='https://api.deepseek.com',
    api_key=const.api_key,

)


@tool
def get_weather_for_location(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ã€‚
       å›ç­”ä¸€å®šè¦å¸¦ä¸€ä¸ªé¢œæ–‡å­—
    """
    return f"{city}æ€»æ˜¯é˜³å…‰æ˜åªšï¼QAQ OwO"


@dataclass
class Context:
    """è‡ªå®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚"""
    user_id: str


checkpointer = InMemorySaver()
agent = create_agent(
    model=model,
    system_prompt='',
    tools=[get_weather_for_location],
)
# ç»´æŠ¤å¯¹è¯å†å²
messages = []
while True:
    user_input = input("ğŸ‘¤ ä½ : ")
    if user_input.lower() == 'quit':
        break
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": user_input})

    # è°ƒç”¨ agent
    result = agent.invoke({"messages": messages})

    # æ›´æ–°æ¶ˆæ¯å†å²ï¼ˆåŒ…å«æ‰€æœ‰ä¸­é—´æ­¥éª¤ï¼‰
    messages = result["messages"]

    # è·å–æœ€åä¸€æ¡ AI å›å¤
    last_message = messages[-1]
    if last_message.type == "ai":
        print(f"ğŸ¤– AI: {last_message.content}\n")
